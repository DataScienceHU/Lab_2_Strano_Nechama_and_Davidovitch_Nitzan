library(ggthemes)
library(stringr)
library(tidytext)
library(rvest)
url <- 'https://www.gutenberg.org/files/2701/2701-h/2701-h.htm'
webpage <- read_html(url)
first_sentence <- webpage %>% html_nodes("div") %>% html_text()
first_sentence[1]
all_words_html <- webpage %>% html_text() %>% str_split(",|\\.|[:space:]")
all_words_html <- all_words_html[[1]]
words <- all_words_html[all_words_html!=""]
print(length(words))
len_words <- str_length(words)
words_dist<- table(len_words)/length(words)
barplot(words_dist, main = "Distribution of word lenghts", xlab = "Lenght of word", ylab = "Distribution of word length")
median(len_words)
mean(len_words)
max(len_words)
#most common
sort(table(words), decreasing = TRUE)
sort(table(words), decreasing = TRUE)[1:10]
chapters <- webpage %>% html_nodes("h2") %>% html_text() %>% str_split("CHAPTER")
chapters <- webpage %>% html_nodes("/n /n /n /n /n /n /n ") %>% html_text() %>% str_split("CHAPTER")
chapters <- webpage %>% html_nodes("\n \n \n \n \n \n \n ") %>% html_text() %>% str_split("CHAPTER")
chapters <- webpage %>%
html_nodes("\n \n \n \n \n \n \n ") %>%
html_text() %>%
str_split("CHAPTER")
chapters <- webpage %>%
html_nodes("\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n") %>%
html_text()
chapters <- webpage %>%
html_text() %>%
html_nodes("\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n")
chapters <- webpage %>%
html_text() %>%
str_split("\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n")
chapters
word_freq <- sort(table(words), decreasing = TRUE)
word_freq
words
chapters <- webpage %>%
html_text() %>%
str_split("\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n")
len_words <- str_length(words)
words_dist<- table(len_words)/length(words)
barplot(words_dist, main = "Distribution of word lenghts", xlab = "Lenght of word", ylab = "Distribution of word length")
median(len_words)
mean(len_words)
max(len_words)
#most common
elements <- strsplit(webpage,split = '\n\\s\\s\\s\\s\\s\\s(CHAPTER)|\n\\s\\s\\s\\s\\s\\s\\s\\s(ETYMOLOGY)|\n\\s\\s\\s\\s\\s\\s\\s\\s(EXTRACTS)|\n\\s\\s\\s\\s\\s\\s(Epilogue)|(\\\\\\* END)')[[1]]
elements <- strsplit(first_sentence,split = '\n\\s\\s\\s\\s\\s\\s(CHAPTER)|\n\\s\\s\\s\\s\\s\\s\\s\\s(ETYMOLOGY)|\n\\s\\s\\s\\s\\s\\s\\s\\s(EXTRACTS)|\n\\s\\s\\s\\s\\s\\s(Epilogue)|(\\\\\\* END)')[[1]]
elements
elements <- strsplit(first_sentence,split = '\n\\s\\s\\s\\s\\s\\s(CHAPTER)|\n\\s\\s\\s\\s\\s\\s\\s\\s(ETYMOLOGY)|\n\\s\\s\\s\\s\\s\\s\\s\\s(EXTRACTS)|\n\\s\\s\\s\\s\\s\\s(Epilogue)|(\\\\\\* END)')
elements
first_sentence
book <- webpage %>% html_nodes("div") %>% html_text()
first_sentence<- book[1]
first_sentence<- book[1]
first_sentence
elements <- strsplit(book,split = '\n\\s\\s\\s\\s\\s\\s(CHAPTER)|\n\\s\\s\\s\\s\\s\\s\\s\\s(ETYMOLOGY)|\n\\s\\s\\s\\s\\s\\s\\s\\s(EXTRACTS)|\n\\s\\s\\s\\s\\s\\s(Epilogue)|(\\\\\\* END)')
elements
all_words <- webpage %>% html_text() %>% str_split(",|\\.|[:space:]")
all_words <- all_words_html[[1]]
words <- all_words[all_words_html!=""]
print(length(words))
chapters <- book %>%
html_text() %>%
str_split("\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n")
elements <- strsplit(book,split = '\n\\s\\s\\s\\s\\s\\s(CHAPTER)|\n\\s\\s\\s\\s\\s\\s\\s\\s(ETYMOLOGY)|\n\\s\\s\\s\\s\\s\\s\\s\\s(EXTRACTS)|\n\\s\\s\\s\\s\\s\\s(Epilogue)|(\\\\\\* END)')
elements
elements <- strsplit(book,split = '\n\\s\\s\\s\\s\\s\\s(CHAPTER)|\n\\s\\s\\s\\s\\s\\s\\s\\s(ETYMOLOGY)|\n\\s\\s\\s\\s\\s\\s\\s\\s(EXTRACTS)|\n\\s\\s\\s\\s\\s\\s(Epilogue)|(\\\\\\* END)')[[1]]
elements
elements <- strsplit(book,split = '\n\\s\\s\\s\\s\\s\\s(CHAPTER)|\n\\s\\s\\s\\s\\s\\s\\s\\s(ETYMOLOGY)|\n\\s\\s\\s\\s\\s\\s\\s\\s(EXTRACTS)|\n\\s\\s\\s\\s\\s\\s(Epilogue)|(\\\\\\* END)')[[2]]
elements
elements <- strsplit(book,split = '\n\\s\\s\\s\\s\\s\\s(CHAPTER)|\n\\s\\s\\s\\s\\s\\s\\s\\s(ETYMOLOGY)|\n\\s\\s\\s\\s\\s\\s\\s\\s(EXTRACTS)|\n\\s\\s\\s\\s\\s\\s(Epilogue)|(\\\\\\* END)')
elements
lower<- str_to_lower(book,locale="en")
all_words <- webpage %>% html_text() %>% str_split(",|\\.|[:space:]")
all_words <- all_words_html[[1]]
words <- all_words[all_words_html!=""]
print(length(words))
barplot(words_dist, main = "Distribution of word lenghts", xlab = "Lenght of word", ylab = "Distribution of word length")
book
book<- html_text(html_nodes(webpage,'h3'))
book
book<- html_text(html_nodes(webpage,'p''div','h3'))
book<- html_text(html_nodes(webpage,'p''div''h3'))
book<- html_text(html_nodes(webpage,'p,div, h3'))
book
book<- html_text(html_nodes(webpage,'p,div,h1,h2,h3'))
book
class(book)
chapters <- strsplit(book, split = '\n\n\n\n\n\n\n')[[1]]
chapters <- chapters[2:length(chapters)]
chapters[137] <- strsplit(chapters[137], split = 'END OF THE PROJECT GUTENBERG EBOOK MOBY-DICK; OR THE WHALE')[[1]][1]
chapters
chapters
chapters[137]
chapters
chapters
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse) # This includes dplyr, stringr, ggplot2, ..
library(data.table)
library(ggthemes)
library(stringr)
library(tidytext)
library(rvest)
url <- 'https://www.gutenberg.org/files/2701/2701-h/2701-h.htm'
webpage <- read_html(url)
book <- webpage %>% html_nodes("div") %>% html_text()
first_sentence<- book[1]
lower<- str_to_lower(book,locale="en")
all_words <- webpage %>% html_text() %>% str_split(",|\\.|[:space:]")
all_words <- all_words_html[[1]]
words <- all_words[all_words_html!=""]
print(length(words))
len_words <- str_length(words)
words_dist<- table(len_words)/length(words)
barplot(words_dist, main = "Distribution of word lenghts", xlab = "Lenght of word", ylab = "Distribution of word length")
median(len_words)
mean(len_words)
max(len_words)
#most common
sort(table(words), decreasing = TRUE)
sort(table(words), decreasing = TRUE)[1:10]
book<- html_text(html_nodes(webpage,'p,div,h1,h2,h3'))
chapters <- strsplit(book, split = '\n\n\n\n\n\n\n')[[1]]
chapters <- chapters[2:length(chapters)]
chapters[137] <- strsplit(chapters[137], split = 'END OF THE PROJECT GUTENBERG EBOOK MOBY-DICK; OR THE WHALE')[[1]][1]
word_func {}
sort(table(words), decreasing = TRUE)
sort(table(words), decreasing = TRUE)[1:10]
url <- 'https://www.gutenberg.org/files/2701/2701-h/2701-h.htm'
webpage <- read_html(url)
book <- webpage %>% html_nodes("div") %>% html_text()
first_sentence<- book[1]
lower<- str_to_lower(book,locale="en")
all_words <- webpage %>% html_text() %>% str_split(",|\\.|[:space:]")
all_words <- all_words_html[[1]]
words <- all_words[all_words_html!=""]
print(length(words))
len_words <- str_length(words)
words_dist<- table(len_words)/length(words)
barplot(words_dist, main = "Distribution of word lenghts", xlab = "Lenght of word", ylab = "Distribution of word length")
median(len_words)
mean(len_words)
max(len_words)
#most common
len_words <- str_length(words)
words_dist<- table(len_words)/length(words)
barplot(words_dist, main = "Distribution of word lenghts", xlab = "Lenght of word", ylab = "Distribution of word length")
median(len_words)
mean(len_words)
max(len_words)
#most common
sort(table(words), decreasing = TRUE)
sort(table(words), decreasing = TRUE)[1:10]
lower<- str_to_lower(book,locale="en")
all_words <- book %>% html_text() %>% str_split(",|\\.|[:space:]")
lower<- str_to_lower(book,locale="en")
all_words <- webpage %>% html_text() %>% str_split(",|\\.|[:space:]")
all_words <- all_words_html[[1]]
words <- all_words[all_words_html!=""]
print(length(words))
len_words <- str_length(words)
words_dist<- table(len_words)/length(words)
barplot(words_dist, main = "Distribution of word lenghts", xlab = "Lenght of word", ylab = "Distribution of word length")
median(len_words)
mean(len_words)
max(len_words)
#most common
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse) # This includes dplyr, stringr, ggplot2, ..
library(data.table)
library(ggthemes)
library(stringr)
library(tidytext)
library(rvest)
url <- 'https://www.gutenberg.org/files/2701/2701-h/2701-h.htm'
webpage <- read_html(url)
book <- webpage %>% html_nodes("div") %>% html_text()
first_sentence<- book[1]
lower<- str_to_lower(book,locale="en")
all_words <- webpage %>% html_text() %>% str_split(",|\\.|[:space:]")
all_words <- all_words_html[[1]]
words <- all_words[all_words_html!=""]
print(length(words))
len_words <- str_length(words)
words_dist<- table(len_words)/length(words)
barplot(words_dist, main = "Distribution of word lenghts", xlab = "Lenght of word", ylab = "Distribution of word length")
median(len_words)
mean(len_words)
max(len_words)
#most common
sort(table(words), decreasing = TRUE)
sort(table(words), decreasing = TRUE)[1:10]
book<- html_text(html_nodes(webpage,'p,div,h1,h2,h3'))
chapters <- strsplit(book, split = '\n\n\n\n\n\n\n')[[1]]
chapters <- chapters[2:length(chapters)]
chapters[137] <- strsplit(chapters[137], split = 'END OF THE PROJECT GUTENBERG EBOOK MOBY-DICK; OR THE WHALE')[[1]][1]
word_func {}
webpage <- read_html("https://www.gutenberg.org/files/2701/2701-h/2701-h.htm#link2HCH0004")
moby_book <- html_text(html_nodes(webpage, 'title,p,h1,h2,h3'))
moby_book
moby_book <- paste(moby_book, collapse = " ")
moby_book
print(moby_book[1])
webpage <- read_html("https://www.gutenberg.org/files/2701/2701-h/2701-h.htm#link2HCH0004")
moby_lines <- html_text(html_nodes(webpage, 'title,p,h1,h2,h3'))
moby_book <- paste(moby_lines, collapse = " ")
print(moby_book[1])
webpage <- read_html("https://www.gutenberg.org/files/2701/2701-h/2701-h.htm#link2HCH0004")
moby_lines <- html_text(html_nodes(webpage, 'title,p,h1,h2,h3'))
moby_book <- paste(moby_lines, collapse = " ")
print(moby_book[1])
print(moby_book[1][1])
webpage <- read_html("https://www.gutenberg.org/files/2701/2701-h/2701-h.htm#link2HCH0004")
moby_lines <- html_text(html_nodes(webpage, 'title,p,h1,h2,h3'))
mobybook <- paste(moby_lines, collapse = " ")
strsplit(mobybook,"\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n")
chapters = strsplit(mobybook,"CHAPTER")
strsplit(mobybook,"\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n")
url <- '"https://www.gutenberg.org/files/2701/2701-h/2701-h.htm#link2HCH0004"'
webpage <- read_html(url)
url <- 'https://www.gutenberg.org/files/2701/2701-h/2701-h.htm#link2HCH0004'
webpage <- read_html(url)
mobybook = html_text(webpage)
book <- webpage %>% html_nodes("div") %>% html_text()
class(book)
book[1]
all_words_html <- webpage %>% html_text() %>% str_split(",|\\.|[:space:]")
all_words_html <- all_words_html[[1]]
words <- all_words_html[all_words_html!=""]
print(length(words))
len_words <- str_length(words)
words_dist<- table(len_words)/length(words)
barplot(words_dist, main = "Distribution of word lenghts", xlab = "Lenght of word", ylab = "Distribution of word length")
median(len_words)
mean(len_words)
max(len_words)
#most common
sort(table(words), decreasing = TRUE)[1]
sort(table(words), decreasing = TRUE)[1:10]
webpage <- read_html("https://www.gutenberg.org/files/2701/2701-h/2701-h.htm#link2HCH0004")
moby_lines <- html_text(html_nodes(webpage, 'title,p,h1,h2,h3'))
mobybook <- paste(moby_lines, collapse = " ")
strsplit(mobybook,"\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n")
chapters = strsplit(mobybook,"CHAPTER")
chapters[[1]][200]
chapters = chapters[[1]][137:length(chapters[[1]])]
length(chapters)
#"\r\n    \r\n    \r\n      \r\n       \r\n    \r\n    \r\n      \r\n    \r\n      "
#webpage
#elements <- strsplit(book,split ='\n\n\n\n\n\n')[[1]]
#chapters <- elements[2:length(elements)]
#chapters = webpage %>% html_text()  %>% str_split("\r\n    \r\n    \r\n      \r\n       \r\n    \r\n    \r\n      \r\n    \r\n      ")
#chapters2 = webpage %>% html_text()  %>% str_split("\r\n     \r\n    \r\n      \r\n       \r\n    \r\n    \r\n      \r\n    \r\n      ")
#chapters = webpage %>% html_text()  %>% str_split("\r\n    \r\n    \r\n      \r\n       \r\n    \r\n    \r\n      \r\n    \r\n      ")
#chapters[[1]][14]
#chapters2[[1]][2]
#all_chapters = c(chapters,chapters2)
#all_chapters[[2]]
chapters = webpage %>% html_text()  %>% str_split("\r\n    \r\n    \r\n      \r\n       \r\n    \r\n    \r\n      \r\n    \r\n      ")
chapters
chapters<- strsplit(mobybook,"\r\n\n\r\n\n\r \r \r\n\n\r\n\r\n\n\n\n\n\r\n\r")
chapters
chapter<- chapters[[1]]
chapter
elements <- strsplit(mobybook,split = '\n\\s\\s\\s\\s\\s\\s(CHAPTER)|\n\\s\\s\\s\\s\\s\\s\\s\\s(ETYMOLOGY)|\n\\s\\s\\s\\s\\s\\s\\s\\s(EXTRACTS)|\n\\s\\s\\s\\s\\s\\s(Epilogue)|(\\\\\\* END)')[[1]]
elements
elements[[1]]
elements[[1]][13]
elements[[1]][14]
chapter<- chapters[[1]][13]
chapter
chapter<- chapters[[1]]
chapter
elements <- strsplit(mobybook,split = '\n\\s\\s\\s\\s\\s\\s(CHAPTER)|\n\\s\\s\\s\\s\\s\\s\\s\\s(ETYMOLOGY)|\n\\s\\s\\s\\s\\s\\s\\s\\s(EXTRACTS)|\n\\s\\s\\s\\s\\s\\s(Epilogue)|(\\\\\\* END)')
elements
webpage <- read_html("https://www.gutenberg.org/files/2701/2701-h/2701-h.htm#link2HCH0004")
moby_lines <- html_text(html_nodes(webpage, 'title,p,h1,h2,h3'))
mobybook <- paste(moby_lines, collapse = " ")
#chapters<- strsplit(mobybook,"\r\n\n\r\n\n\r \r \r\n\n\r\n\r\n\n\n\n\n\r\n\r")
#chapter<- chapters[[1]]
elements <- strsplit(mobybook,split = '\n\\s\\s\\s\\s\\s\\s(CHAPTER)|\n\\s\\s\\s\\s\\s\\s\\s\\s(ETYMOLOGY)|\n\\s\\s\\s\\s\\s\\s\\s\\s(EXTRACTS)|\n\\s\\s\\s\\s\\s\\s(Epilogue)|(\\\\\\* END)')[[1]]
elements
elements[[1]][2]
lower_text <- str_to_lower(book, locale = "en")
all_words_html <-   lower_text%>% str_split(",|\\.|[:space:]")
all_words_html <- all_words_html[[1]]
words <- all_words_html[all_words_html!=""]
print(length(words))
lower_text <- str_to_lower(book, locale = "en")
all_words_html <- webpage %>% html_text() %>% str_split(",|\\.|[:space:]")
all_words_html <- all_words_html[[1]]
words <- all_words_html[all_words_html!=""]
print(length(words))
book[1]
book
lower_text <- str_to_lower(book, locale = "en")
all_words_html <- lower_text %>% str_split(",|\\.|[:space:]")
all_words_html <- all_words_html[[1]]
words <- all_words_html[all_words_html!=""]
print(length(words))
print(length(all_words_html))
words <- all_words_html[! all_words_html %in% c("")]
print(length(all_words_html))
all_words_html <- lower_text %>% str_split("[,|\\.|[:space:]]")
all_words_html <- all_words_html[[1]]
all_words_html <- lower_text %>% str_split("[,|\\.|[:space:]]")
words <- all_words_html[! all_words_html %in% c("")]
print(length(all_words_html))
len_words <- str_length(words)
words_dist<- table(len_words)/length(words)
barplot(words_dist, main = "Distribution of word lenghts", xlab = "Lenght of word", ylab = "Distribution of word length")
median(len_words)
barplot(words_dist, main = "Distribution of word lenghts", xlab = "Lenght of word", ylab = "Distribution of word length")
all_words_html <- lower_text %>% unlist(str_split("[,|\\.|[:space:]]"))
all_words_html <- lower_text %>% unlist(pattern = str_split("[,|\\.|[:space:]]"))
all_words_html <- unlist(lower_text,pattern = str_split("[,|\\.|[:space:]]"))
all_words_html <- unlist(lower_text,split = "[,|\\.|[:space:]]")
all_words_html <- unlist(lower_text,split = "[ ,.\r\n]")
all_words_html <- unlist(strsplit(lower_text, split = "[ ,.\r\n]"))
words <- all_words_html[! all_words_html %in% c("")]
print(length(all_words_html))
all_words_html <- unlist(strsplit(lower_text, split = "[ ,.\r\n]"))
words <- all_words_html[! all_words_html %in% c("")]
print(length(all_words_html))
len_words <- str_length(words)
words_dist<- table(len_words)/length(words)
barplot(words_dist, main = "Distribution of word lenghts", xlab = "Lenght of word", ylab = "Distribution of word length")
lower_text <- str_to_lower(book, locale = "en")
all_words_html <- webpage %>% html_text() %>% str_split(",|\\.|[:space:]")
all_words_html <- all_words_html[[1]]
words <- all_words_html[all_words_html!=""]
print(length(words))
mobybook = str_replace_all(mobybook, "[^[:alnum:]]", "")    # Delete non-alphanumeric
mobybook
mobybook = str_replace_all(mobybook, "[^[:alnum:]]")
mobybook = str_replace_all(mobybook, "[^[:alnum:]]", " ")
mobybook = str_replace_all(mobybook, "[^[:alnum:]]", " ")
mobybook
str_replace_all(mobybook, "[[:punct:]]", "")
book <- str_replace_all(mobybook, "[[:punct:]]", "")
book
book <- str_replace_all(mobybook, "[[:punct:]]", " ")
book
class(mobybook)
book <- str_replace_all(mobybook, "[[:punct:]]", "")
gsub("[^[:alnum:][:space:]]","",book)
gsub("[^[:alnum:][:space:]]","",mobybook)
#book <- str_replace_all(mobybook, "[[:punct:]]", "")
gsub("[^[:alnum:][:space:]]","",mobybook)
#book <- str_replace_all(mobybook, "[[:punct:]]", "")
gsub("[^[:alnum:][:space:]]",mobybook)
#book <- str_replace_all(mobybook, "[[:punct:]]", "")
gsub("[^[:alnum:][:space:]]"," ",mobybook)
#book <- str_replace_all(mobybook, "[[:punct:]]", "")
gsub("[^[:alnum:]"," ",mobybook)
#book <- str_replace_all(mobybook, "[[:punct:]]", "")
gsub("[:alnum:]"," ",mobybook)
#book <- str_replace_all(mobybook, "[[:punct:]]", "")
mobybook
mobybook
gsub("[:alnum:]"," ",mobybook)
mobybook
mobybook
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse) # This includes dplyr, stringr, ggplot2, ..
library(data.table)
library(ggthemes)
library(stringr)
library(tidytext)
library(rvest)
url <- 'https://www.gutenberg.org/files/2701/2701-h/2701-h.htm'
webpage <- read_html(url)
mobybook = html_text(webpage)
book <- webpage %>% html_nodes("div") %>% html_text()
class(book)
book[1]
#lower_text <- str_to_lower(book, locale = "en")
all_words_html <- webpage %>% html_text() %>% str_split(",|\\.|[:space:]")
all_words_html <- all_words_html[[1]]
words <- all_words_html[all_words_html!=""]
print(length(words))
len_words <- str_length(words)
words_dist<- table(len_words)/length(words)
barplot(words_dist, main = "Distribution of word lenghts", xlab = "Lenght of word", ylab = "Distribution of word length")
median(len_words)
mean(len_words)
max(len_words)
#most common
sort(table(words), decreasing = TRUE)[1]
sort(table(words), decreasing = TRUE)[1:10]
webpage <- read_html("https://www.gutenberg.org/files/2701/2701-h/2701-h.htm#link2HCH0004")
moby_lines <- html_text2(html_nodes(webpage, 'title,p,h1,h2,h3'))
mobybook <- paste(moby_lines, collapse = " ")
mobybook = strsplit(mobybook,"\r \r \r \r \r ")
mobybook[[1]][2]
chapters = strsplit(mobybook,"CHAPTER")
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse) # This includes dplyr, stringr, ggplot2, ..
library(data.table)
library(ggthemes)
library(stringr)
library(tidytext)
library(rvest)
url <- 'https://www.gutenberg.org/files/2701/2701-h/2701-h.htm'
webpage <- read_html(url)
mobybook = html_text(webpage)
book <- webpage %>% html_nodes("div") %>% html_text()
class(book)
book[1]
all_words_html <- webpage %>% html_text() %>% str_split(",|\\.|[:space:]")
all_words_html <- all_words_html[[1]]
words <- all_words_html[all_words_html!=""]
print(length(words))
```
mobybook_clean
mobybook_clean <- str_replace_all(mobybook, "[^a-zA-Z]", " ")
mobybook_clean
mobybook_clean <-strsplit(mobybook," ")
mobybook_clean
mobybook_clean<- tolower(mobybook_clean)
mobybook_clean
mobybook_clean<- tolower(mobybook_clean)
mobybook_clean
mobybook_clean <-strsplit(mobybook," ")
mobybook_clean
mobybook_clean
mobybook_clean <- str_replace_all(mobybook, "[^a-zA-Z]", " ")
mobybook_clean
mobybook_<-strsplit(mobybook," ")
mobybook_
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse) # This includes dplyr, stringr, ggplot2, ..
library(data.table)
library(ggthemes)
library(stringr)
library(tidytext)
library(rvest)
url <- 'https://www.gutenberg.org/files/2701/2701-h/2701-h.htm'
webpage <- read_html(url)
mobybook = html_text(webpage)
book <- webpage %>% html_nodes("div") %>% html_text()
class(book)
book[1]
all_words_html <- webpage %>% html_text() %>% str_split(",|\\.|[:space:]")
all_words_html <- all_words_html[[1]]
words <- all_words_html[all_words_html!=""]
print(length(words))
```
mobybook_clean
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse) # This includes dplyr, stringr, ggplot2, ..
library(data.table)
library(ggthemes)
library(stringr)
library(tidytext)
library(rvest)
url <- 'https://www.gutenberg.org/files/2701/2701-h/2701-h.htm'
webpage <- read_html(url)
mobybook = html_text(webpage)
book <- webpage %>% html_nodes("div") %>% html_text()
class(book)
book[1]
#lower_text <- str_to_lower(book, locale = "en")
all_words_html <- webpage %>% html_text() %>% str_split(",|\\.|[:space:]")
all_words_html <- all_words_html[[1]]
words <- all_words_html[all_words_html!=""]
print(length(words))
```
mobybook_clean = str_replace_all(mobybook, "[^a-zA-Z]", " ")
mobybook_clean
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse) # This includes dplyr, stringr, ggplot2, ..
library(data.table)
library(ggthemes)
library(stringr)
library(tidytext)
library(rvest)
url <- 'https://www.gutenberg.org/files/2701/2701-h/2701-h.htm'
webpage <- read_html(url)
mobybook = html_text(webpage)
sort(table(words), decreasing = TRUE)[1]
sort(table(words), decreasing = TRUE)[1:10]
sort(table(words), decreasing = TRUE)[1]
sort(table(words), decreasing = TRUE)[1:10]
length(chapters)
chapters = chapters
class(mobybook)
word_frequencies = function(word,chapters){
freq_vec = c()
for (i in length(array)){
chapter_words <- strsplit(chapters[[1]][i],",|\\.|[:space:]")
#all_words_html <- all_words_html[[1]]
chapter_words <- chapter_words[all_words_html!=""]
total_words = length(chapter_words)
word_freq = sort(table(words), decreasing = TRUE)
freq = word_freq[word_freq[,1]==word,2]
freq_vec = c(freq_vec,freq/total_words)
}
return(freq_vec)
}
word_frequencies("Ahab",chapters)
<<<<<<< Updated upstream
mobybook_clean = str_replace_all(mobybook, "[^a-zA-Z]", " ")
mobybook_clean
mobybook = html_text(webpage)
mobybook
