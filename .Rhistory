knitr::opts_chunk$set(echo = TRUE)
library(tidyverse) # This includes dplyr, stringr, ggplot2, ..
library(data.table)
library(ggthemes)
library(stringr)
library(tidytext)
library(rvest)
options(scipen=alpha)
url <- 'https://www.gutenberg.org/files/2701/2701-h/2701-h.htm'
webpage <- read_html(url)
#lower_text <- str_to_lower(book, locale = "en")
all_words_html <- webpage %>% html_text() %>% str_split(",|\\.|[:space:]")
len_words <- str_length(words)
words_dist<- table(len_words)/length(words)
barplot(words_dist, main = "Distribution of word lenghts", xlab = "Lenght of word", ylab = "Distribution of word length")
#median
median(len_words)
#mean
mean(len_words)
#longest
max(len_words)
#most common
sort(table(words), decreasing = TRUE)[1]
sort(table(words), decreasing = TRUE)[1:10]
webpage <- read_html("https://www.gutenberg.org/files/2701/2701-h/2701-h.htm#link2HCH0004")
webpage
webpage <- read_html("https://www.gutenberg.org/files/2701/2701-h/2701-h.htm#link2HCH0004")
webpage <- read_html("https://www.gutenberg.org/files/2701/2701-h/2701-h.htm#link2HCH0004")
url <- 'https://www.gutenberg.org/files/2701/2701-h/2701-h.htm'
webpage <- read_html(url)
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse) # This includes dplyr, stringr, ggplot2, ..
library(data.table)
library(ggthemes)
library(stringr)
library(tidytext)
library(rvest)
options(scipen=alpha)
url <- 'https://www.gutenberg.org/files/2701/2701-h/2701-h.htm'
webpage <- read_html(url)
book <- webpage %>% html_nodes("div") %>% html_text()
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse) # This includes dplyr, stringr, ggplot2, ..
library(data.table)
library(ggthemes)
library(stringr)
library(tidytext)
library(rvest)
options(scipen=alpha)
url <- 'https://www.gutenberg.org/files/2701/2701-h/2701-h.htm'
webpage <- read_html(url)
webpage <- read_html(url)
mobybook = html_text(webpage)
webpage <- read_html(url)
url <- 'https://www.gutenberg.org/files/2701/2701-h/2701-h.htm'
webpage <- read_html(url)
mobybook = html_text(webpage)
book <- webpage %>% html_nodes("div") %>% html_text()
book[1]
#lower_text <- str_to_lower(book, locale = "en")
all_words_html <- webpage %>% html_text() %>% str_split(",|\\.|[:space:]")
all_words_html <- all_words_html[[1]]
words <- all_words_html[all_words_html!=""]
print(length(words))
len_words <- str_length(words)
words_dist<- table(len_words)/length(words)
barplot(words_dist, main = "Distribution of word lenghts", xlab = "Lenght of word", ylab = "Distribution of word length")
#median
median(len_words)
#mean
mean(len_words)
#longest
max(len_words)
#most common
sort(table(words), decreasing = TRUE)[1]
sort(table(words), decreasing = TRUE)[1:10]
webpage <- read_html("https://www.gutenberg.org/files/2701/2701-h/2701-h.htm#link2HCH0004")
webpage <- read_html("https://www.gutenberg.org/files/2701/2701-h/2701-h.htm#link2HCH0004")
webpage <- read_html("https://www.gutenberg.org/files/2701/2701-h/2701-h.htm#link2HCH0004")
moby_lines <- html_text2(html_nodes(webpage, 'title,p,h1,h2,h3'))
mobybook <- paste(moby_lines, collapse = " ")
chapters = strsplit(mobybook,"\r \r \r \r \r ")
#etymology =
chapters[[1]][1] <-  sub(".*\r \r ETYMOLOGY.\r \r","",chapters[[1]][1])
chapters = chapters[[1]][1:137]
#add a graph of words per chapter
word_amount = function(chapters){
for (i in 1:length(chapters)){
print(chapters[i])
all_words_c <- chapters[i] %>% str_split(",|\\.|[:space:]")
}
return(all_words_c)
}
num_word <- word_amount(chapters)
webpage <- read_html("https://www.gutenberg.org/files/2701/2701-h/2701-h.htm#link2HCH0004")
moby_lines <- html_text2(html_nodes(webpage, 'title,p,h1,h2,h3'))
mobybook <- paste(moby_lines, collapse = " ")
chapters = strsplit(mobybook,"\r \r \r \r \r ")
#etymology =
chapters[[1]][1] <-  sub(".*\r \r ETYMOLOGY.\r \r","",chapters[[1]][1])
chapters = chapters[[1]][1:137]
#add a graph of words per chapter
word_amount = function(chapters){
for (i in 1:length(chapters)){
print(chapters[i])
all_words_c <- chapters[i] %>% str_split(",|\\.|[:space:]")
}
return(all_words_c)
}
num_word <- word_amount(chapters)
word_amount = function(chapters){
for (i in 1:length(chapters)){
all_words_c <- chapters[i] %>% str_split(",|\\.|[:space:]")
}
all_words_c_clean = str_replace_all(all_words_c, "[^a-zA-Z]", " ")
return(all_words_c)
}
num_word <- word_amount(chapters)
#add a graph of words per chapter
word_amount = function(chapters){
for (i in 1:length(chapters)){
all_words_c <- chapters[i] %>% str_split(",|\\.|[:space:]")
all_words_c <- as.vector(all_words_c)
}
all_words_c_clean = str_replace_all(all_words_c, "[^a-zA-Z]", " ")
return(all_words_c)
}
num_word <- word_amount(chapters)
#add a graph of words per chapter
word_amount = function(chapters){
for (i in 1:length(chapters)){
all_words_c <- chapters[i] %>% str_split(",|\\.|[:space:]")
print(class(all_words_c))
}
all_words_c_clean = str_replace_all(all_words_c, "[^a-zA-Z]", " ")
return(all_words_c)
}
num_word <- word_amount(chapters)
words_chap <- chapters[chapters!=""]
words_chap
chapters
chapters[1]
lengths(gregexpr("\\W+", chapters[1]
)) + 1
chap_words <- lengths(gregexpr("\\W+", chapters[1]
)) + 1
a_list = "one ' let's go "
chap_words <- lengths(gregexpr("\\W+", a_list
)) + 1
chap_words
a_list = "one ' let's go "
chap_words <- lengths(gregexpr("[^a-zA-Z]", a_list
)) + 1
chap_words
all_words_html
mobybook
all_words_html
mobybook[1]
mobybook[[1]][1]
mobybook[[1]][2]
words <- chapters[chapters!=""]
words
chapters = strsplit(mobybook,"\r \r \r \r \r ")
#etymology =
chapters[[1]][1] <-  sub(".*\r \r ETYMOLOGY.\r \r","",chapters[[1]][1])
chapters = chapters[[1]][1:137]
#add a graph of words per chapter
word_amount = function(chapters){
for (i in 1:length(chapters)){
all_words_c <- chapters[i] %>% str_split(",|\\.|[:space:]")
print(all_words_c)
print(class(all_words_c))
}
all_words_c_clean = str_replace_all(all_words_c, "[^a-zA-Z]", " ")
return(all_words_c)
}
num_word <- word_amount(chapters)
word_amount = function(chapters){
for (i in 1:length(chapters)){
vec_words=c()
all_words_c <- chapters[i] %>% str_split(",|\\.|[:space:]")
words <- all_words_c[all_words_c!=""]
vec_words = c(vec_words,count(all_words_c))
}
#all_words_c_clean = str_replace_all(all_words_c, "[^a-zA-Z]", " ")
return(vec_words)
}
num_word <- word_amount(chapters)
word_amount = function(chapters){
for (i in 1:length(chapters)){
vec_words=c()
all_words_c <- chapters[i] %>% str_split(",|\\.|[:space:]")
words <- all_words_c[all_words_c!=""]
vec_words = c(vec_words,length(all_words_c))
}
#all_words_c_clean = str_replace_all(all_words_c, "[^a-zA-Z]", " ")
return(vec_words)
}
num_word <- word_amount(chapters)
num_word
word_amount = function(chapters){
for (i in 1:length(chapters)){
vec_words=c()
all_words_c <- chapters[i] %>% str_split(",|\\.|[:space:]")
all_words_c_clean = str_replace_all(all_words_c, "[^a-zA-Z]", " ")
words <- all_words_c[all_words_c!=""]
vec_words = c(vec_words,length(all_words_c))
}
return(vec_words)
}
num_word <- word_amount(chapters)
word_amount = function(chapters){
for (i in 1:length(chapters)){
vec_words=c()
all_words_c <- chapters[i] %>% str_split(",|\\.|[:space:]")
words <- all_words_c[all_words_c!=""]
vec_words = c(vec_words,length(words))
}
return(vec_words)
}
num_word <- word_amount(chapters)
num_word
chapters_1 <- chapters[[1]]
words <- chapters_1[chapters_1!=""]
print(length(words))
words
chapters_1 <- chapters[[1]]
words_c <- chapters_1 %>% str_split(",|\\.|[:space:]")
words_c
words <- words_c[words_c!=""]
words
print(length(words))
words[1]
words[[1]][1]
words[[1]][2]
words[[1]][3]
words[[1]]
words[[2]]
words[[1]]
print(length(words[[1]]))
#add a graph of words per chapter
word_amount = function(chapters){
for (i in 1:length(chapters)){
vec_words=c()
all_words_c <- chapters[i] %>% str_split(",|\\.|[:space:]")
words <- all_words_c[all_words_c!=""]
for i in 1:
add a graph of words per chapter
word_amount = function(chapters){
for (i in 1:length(chapters)){
vec_words=c()
all_words_c <- chapters[i] %>% str_split(",|\\.|[:space:]")
words <- all_words_c[all_words_c!=""]
vec_words = c(vec_words,length(words[[1]]))
}
return(vec_words)
}
num_word <- word_amount(chapters)
num_word
word_amount = function(chapters){
for (i in 1:length(chapters)){
vec_words=c()
all_words_c <- chapters[i] %>% str_split(",|\\.|[:space:]")
words <- all_words_c[all_words_c!=""]
vec_words = append(vec_words, length(words[[1]]), i)
}
return(vec_words)
}
num_word <- word_amount(chapters)
num_word
length(chapters)
length(chapters)
chapters[1]
chapters[2]
words_c <- chapters[1] %>% str_split(",|\\.|[:space:]")
words_c
words <- words_c[words_c!=""]
words
words <- words_c[words_c!=" "]
words
words_c <- chapters[1] %>% str_split(",|\\.|[:space:]")
words <- words_c[words_c!=""]
words
print(length(words[[1]]))
words
words_c[names(words_c) %in% "" == FALSE]
new <- words_c[names(words_c) %in% "" == FALSE]
new
new <- words_c[names(words_c) %in% "" == TRUE]
new
new <- words_c[words_c %in% "" == FALSE]
new
new <- words_c[words_c %in% "" == TRUE]
new <- words_c[words_c %in% "" == TRUE]
words_c <- chapters[1] %>% str_split(",|\\.|[:space:]")
new <- words_c[words_c %in% "" == TRUE]
new
new <- words_c[words_c %in% "" == FALSE]
new
word_amount = function(chapters){
for (i in 1:length(chapters)){
vec_words=c()
all_words_c <- chapters[i] %>% str_split(",|\\.|[:space:]")
words <- all_words_c[all_words_c!=""]
vec_words = append(vec_words, length(words[[i]]), i)
}
return(vec_words)
}
num_word <- word_amount(chapters)
vec = c(1:137)
vec
c[1] = 2
c[1] = c(2)
c[1] = 7
word_amount = function(chapters){
for (i in 1:length(chapters)){
vec_words=c(1:137)
all_words_c <- chapters[i] %>% str_split(",|\\.|[:space:]")
words <- all_words_c[all_words_c!=""]
vec_words = replace(vec_words, x==i, length(words[[1]]))
}
return(vec_words)
}
num_word <- word_amount(chapters)
num_word
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse) # This includes dplyr, stringr, ggplot2, ..
library(data.table)
library(ggthemes)
library(stringr)
library(tidytext)
library(rvest)
options(scipen=alpha)
url <- 'https://www.gutenberg.org/files/2701/2701-h/2701-h.htm'
webpage <- read_html(url)
mobybook = html_text(webpage)
book <- webpage %>% html_nodes("div") %>% html_text()
book[1]
#lower_text <- str_to_lower(book, locale = "en")
all_words_html <- webpage %>% html_text() %>% str_split(",|\\.|[:space:]")
all_words_html <- all_words_html[[1]]
words <- all_words_html[all_words_html!=""]
print(length(words))
len_words <- str_length(words)
words_dist<- table(len_words)/length(words)
barplot(words_dist, main = "Distribution of word lenghts", xlab = "Lenght of word", ylab = "Distribution of word length")
#median
median(len_words)
#mean
mean(len_words)
#longest
max(len_words)
#most common
sort(table(words), decreasing = TRUE)[1]
sort(table(words), decreasing = TRUE)[1:10]
webpage <- read_html("https://www.gutenberg.org/files/2701/2701-h/2701-h.htm#link2HCH0004")
moby_lines <- html_text2(html_nodes(webpage, 'title,p,h1,h2,h3'))
mobybook <- paste(moby_lines, collapse = " ")
chapters_1 <- webpage %>% html_text() %>% str_split(",|\\.|[:space:]")
chapters_1 <- chapters_1[[1]]
words <- all_words_html[all_words_html!=""]
print(length(words))
chapters = strsplit(mobybook,"\r \r \r \r \r ")
#etymology =
chapters[[1]][1] <-  sub(".*\r \r ETYMOLOGY.\r \r","",chapters[[1]][1])
chapters = chapters[[1]][1:137]
chapters_1 <- chapters[[1]]
words_c <- chapters[1] %>% str_split(",|\\.|[:space:]")
words <- words_c[words_c!=""]
print(length(words[[1]]))
#add a graph of words per chapter
word_amount = function(chapters){
for (i in 1:length(chapters)){
vec_words=c(1:137)
all_words_c <- chapters[i] %>% str_split(",|\\.|[:space:]")
words <- all_words_c[all_words_c!=""]
vec_words = replace(vec_words, x==i, length(words[[1]]))
}
return(vec_words)
}
num_word <- word_amount(chapters)
word_amount = function(chapters){
for (i in 1:length(chapters)){
vec_words=c(1:137)
all_words_c <- chapters[i] %>% str_split(",|\\.|[:space:]")
words <- all_words_c[all_words_c!=""]
vec_words = replace(vec_words, x==i, length(words[[1]]))
}
return(vec_words)
}
num_word <- word_amount(chapters)
word_amount = function(chapters){
for (i in 1:length(chapters)){
vec_words=c(1:137)
all_words_c <- chapters[i] %>% str_split(",|\\.|[:space:]")
words <- all_words_c[all_words_c!=""]
vec_words = replace(vec_words,i, length(words[[1]]))
}
return(vec_words)
}
num_word <- word_amount(chapters)
num_word
word_amount = function(chapters){
for (i in 1:length(chapters)){
vec_words=c(1:137)
all_words_c <- chapters[i] %>% str_split(",|\\.|[:space:]")
words <- all_words_c[all_words_c!=""]
print(length(all_words_c[[1]]))
vec_words = replace(vec_words,i, length(words[[1]]))
}
return(vec_words)
}
num_word <- word_amount(chapters)
chapters_1 <- chapters[[1]]
words_c <- chapters[1] %>% str_split(",|\\.|[:space:]")
words <- words_c[words_c!=""]
print(length(words[[1]]))
vec_words = c(1:3)
vec_words = replace(vec_words,1, length(words[[1]]))
vec_words
word_amount = function(chapters){
for (i in 1:length(chapters)){
vec_words=c(1:137)
all_words_c <- chapters[i] %>% str_split(",|\\.|[:space:]")
words <- all_words_c[all_words_c!=""]
print(length(all_words_c[[1]]))
vec_words = replace(vec_words,i, length(words[[i]]))
}
return(vec_words)
}
num_word <- word_amount(chapters)
word_amount = function(chapters){
for (i in 1:length(chapters)){
vec_words=c(1:137)
all_words_c <- chapters[i] %>% str_split(",|\\.|[:space:]")
words <- all_words_c[all_words_c!=""]
print(length(all_words_c[[1]]))
vec_words = replace(vec_words,i, length(words[[1]]))
}
return(vec_words)
}
num_word <- word_amount(chapters)
word_amount = function(chapters){
for (i in 1:length(chapters)){
vec_words=c(1:137)
all_words_c <- chapters[i] %>% str_split(",|\\.|[:space:]")
words <- all_words_c[all_words_c!=""]
print(length(all_words_c[[1]]))
replace(vec_words,i, length(words[[1]]))
}
return(vec_words)
}
num_word <- word_amount(chapters)
num_word
word_amount = function(chapters){
for (i in 1:length(chapters)){
vec_words=c(1:137)
all_words_c <- chapters[i] %>% str_split(",|\\.|[:space:]")
words <- all_words_c[all_words_c!=""]
print(length(all_words_c[[1]]))
replace(vec_words,vec_words==i, length(words[[1]]))
}
return(vec_words)
}
num_word <- word_amount(chapters)
num_word
word_amount = function(chapters){
print(length(chapters))
for (i in 1:length(chapters)){
vec_words=c(1:137)
all_words_c <- chapters[i] %>% str_split(",|\\.|[:space:]")
words <- all_words_c[all_words_c!=""]
print(length(all_words_c[[1]]))
replace(vec_words,vec_words == i, length(words[[1]]))
}
return(vec_words)
}
num_word <- word_amount(chapters)
word_amount = function(chapters){
for (i in 1:length(chapters)){
vec_words=c(1:length(chapters))
all_words_c <- chapters[i] %>% str_split(",|\\.|[:space:]")
words <- all_words_c[all_words_c!=""]
print(length(all_words_c[[1]]))
replace(vec_words,vec_words == i, length(words[[1]]))
}
return(vec_words)
}
num_word <- word_amount(chapters)
word_amount = function(chapters){
for (i in 1:length(chapters)){
vec_words=c(1:length(chapters))
all_words_c <- chapters[i] %>% str_split(",|\\.|[:space:]")
words <- all_words_c[all_words_c!=""]
print(length(all_words_c[[1]]))
replace(vec_words,vec_words == i, length(all_words_c[[1]]))
}
return(vec_words)
}
num_word <- word_amount(chapters)
num_word
word_amount = function(chapters){
for (i in 1:length(chapters)){
vec_words=c(1:length(chapters))
all_words_c <- chapters[i] %>% str_split(",|\\.|[:space:]")
words <- all_words_c[all_words_c!=""]
print(length(words[[1]]))
replace(vec_words,vec_words == i, length(all_words_c[[1]]))
}
return(vec_words)
}
num_word <- word_amount(chapters)
